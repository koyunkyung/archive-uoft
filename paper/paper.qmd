---
title: "Kamala Harris Rises as the 2024 Election Front Runner: A Poll-of-Polls Forecast"
subtitle: "How Poll Aggregation Reveals US Presidental Race Trends[!!!UPDATE IT TO MAIN RESULTS!!!]"
author: 
  - Yunkyung Ko
thanks: "Code and data are available at: [https://github.com/koyunkyung/us_election_2024](https://github.com/koyunkyung/us_election_2024)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
toc: true
toc-title: "Table of Contents"
toc-depth: 2
toc-location: left
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(readr)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(splines)
library(ggplot2)
library(knitr)
library(kableExtra)
library(gridExtra)
library(here)

raw_elections_data <- read_csv(here::here("data/01-raw_data/raw_elections_data.csv"))
harris_data <- read_csv(here::here("data/02-analysis_data/harris_elections_data.csv"))
```


# Introduction

The US presidential election is an event that receives a lot of international attention due to its far-reaching implications beyond the country's borders. The effects of US elections are not only related to economy and international relations around the world, but also link to social and environmental issues such as climate change [@euromonitor2024]. In the anticipation of the 2024 US electoral competition, this paper is aimed at predicting possible outcomes of the election by analyzing the level of support that Kamala Harris will gain.

We forecast the support of Kamala Harris based on the polling results at the national and state levels, and apply a linear regression and a Bayesian approach. The main parameter of interest is the proportion of vote or support that Harris received in surveys, which is traced over time. By considering the effect of changes in poll-making organizations and geographical distinctions, our objective is to correct for variation across different voter bases with the pooling the polls approach [@poolingpolls]. 

Our initial linear model examining the support for Harris over time suggests that the rate of support remained relatively stable around 47%, with no significant increase or decrease. However large variability was detected, as seen in the spread of points around the fitted line. Consequently, pollster-specific effects and state-level random effects were added to the model but resulted in even higher variations. Some pollsters or states consistently reported higher or lower support for Harris compared to others, proposing that [!!!!!MEANINGFUL RESULT ADDED LATER!!!!!].

These prognostics provide much more than merely forecasting the election in question. Hinting the trajectory the US might take in matters of foreign policy, economics, and global politics, predictions enable stakeholders worldwide to take preemptive measures for the resulted changes of a newly elected government [@csis2024]. As such, this study not only contributes to the domestic political discourse but also provides a valuable tool for global actors seeking to navigate the uncertainty surrounding the 2024 US presidential election[@csis2024].

The paper is structured as follows. Initially, @sec-data and @sec-model explores the data and methodology used, including filtering and modeling techniques applied to the polling data. Following that, @sec-results presents the results from the linear and Bayesian models, while the next section @sec-discussion discusses the broader implications of these findings. Finally, the paper concludes with remarks on future directions for research and applications of these models [@sec-discussion].


# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR] to analyze US presidential polling data from FiveThirtyEight [@fivethirtyeight2024], focusing on support for Kamala Harris. The dataset includes a wide range of poll results from various national and state-level polls, with key variables such as pollster, sample size, percentage of support for Harris, and end date of the poll. Following the guidance of @tellingstories, we compiled the results of each opinion poll over a period of time and compared them taking into account the methodological peculiarities of polling by pollsters and geographical scope of the conducted polls. 

To ensure data quality, we filtered the dataset to include only polls that measured Kamala Harris' support, with a numeric grade of pollster 2.7 or higher for reliability. We also limited the analysis to polls conducted after July 21, 2024, when Harris officially declared her candidacy, and excluded pollsters with fewer than 30 polls to focus on those with sufficient data for robust results.

In performing the analysis, we utilized several R packages. @tidyverse was used for data manipulation and visualization and @rstanarm, @modelsummary was respectively used for Bayesian modeling and generating model summaries. For visualizing results, @ggplot2 was used and @kableExtra helped format tables for presentation. These packages provided a framework for efficient data processing, modeling, and reporting.

(Data last updated on [Day] [Month] 2024.) - [!!! MODIFY AT FINAL !!!]

## Measurement

[!!! MODIFY OBSV. NUMBERS AFTER DATA UPDATES !!!] - ERASE AT FINAL

The original dataset sourced from FiveThirtyEight [@fivethirtyeight2024] aggregates a wide range of poll results (15971 observations, based on dataset available at Oct 21, 22:00). The polls conducted by various polling organizations capture voter preferences by taking a representative sample of the electorate and asking for the voters' candidate of choice. Surveys were conducted at the state and national levels, providing the wide perspective on public feelings across the country.

Each poll represents a predictor of an actual event, namely voter opinion at a particular moment. Nevertheless, like all survey results, the raw data is susceptible to many potential limitations including the following: sampling error, variation in polling methods, distortion because of inappropriate survey responses such as missing data or response from respondents who misunderstood the questions [@tellingstories].

While applying several filters to the original dataset such as restricting to those with a numeric grade of 2.7 or higher or pollsters with more than 30 polls improves data reliability, certain limitations still exist. Selection bias and sampling error remains as a concern, since polls always represent only part of the population. Differences in the way different organizations conducted their polling might introduce more inconsistencies. Finally, by focusing our attention on post-declaration polls only, we exclude earlier trends that could add more insight into how Harris' support has evolved over time. 

## Outcome variables

### pct

The main variable of interest that we aim to forecast is the 'pct' variable, which represents the proportion of vote or support that a candidate received in the poll. @tbl-pctraw1 and @fig-pct2 respectively shows the summary statistics and distribution of the 'pct' variable in the original dataset [@fivethirtyeight2024]. @tbl-pctfilter1 and @fig-pctfilter2 shows the summary statistics and distribution of the same variable, but in the filtered dataset that only comprises of the supporting votes for Harris from relatively high-quality polling organizations. Comparing the summary statistics for the raw data (@tbl-pctraw1) and filtered data (@tbl-pctfilter1), higher numbers were derived from data filtered only by Harris supporters. Also, @fig-pctfilter2 illustrates that a significant number of polls indicate support levels ranging from 40% to 50%, which suggests a stable yet not substantial endorsement. This proposes that Harris possesses a reliable foundational support, although her capacity to obtain a majority remains ambiguous.

```{r}
#| label: tbl-pctraw1
#| tbl-cap: Summary Statistics for the 'pct' Variable (Raw Data)
#| echo: false

# Calculate summary statistics for the 'pct' variable
summary_stats <- raw_elections_data %>%
  summarize(
    mean = mean(pct, na.rm = TRUE),
    median = median(pct, na.rm = TRUE),
    min = min(pct, na.rm = TRUE),
    max = max(pct, na.rm = TRUE),
    sd = sd(pct, na.rm = TRUE),
    n = n()
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```
```{r}
#| label: fig-pct2
#| fig-cap: Distribution of the 'pct' Variable (Raw Data)
#| echo: false

# Plot the distribution of 'pct' using a histogram
ggplot(raw_elections_data, aes(x = pct)) +
  geom_histogram(binwidth = 5, fill = "blue", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "Percentage of Support (pct)",
       y = "Frequency")

```
```{r}
#| label: tbl-pctfilter1
#| tbl-cap: Summary Statistics for the 'pct' Variable (Filtered Data)
#| echo: false

# Calculate summary statistics for the 'pct' variable
summary_stats <- harris_data %>%
  summarize(
    mean = mean(pct, na.rm = TRUE),
    median = median(pct, na.rm = TRUE),
    min = min(pct, na.rm = TRUE),
    max = max(pct, na.rm = TRUE),
    sd = sd(pct, na.rm = TRUE),
    n = n()
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```
```{r}
#| label: fig-pctfilter2
#| fig-cap: Distribution of the 'pct' Variable (Filtered Data)
#| echo: false

# Plot the distribution of 'pct' using a histogram
ggplot(harris_data, aes(x = pct)) +
  geom_histogram(binwidth = 5, fill = "blue", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "Percentage of Support (pct)",
       y = "Frequency")

```


## Predictor variables

### end_date

[!!! MODIFY DATE RANGE AFTER DATA UPDATES !!!] - ERASE AT FINAL

The date variable representing the time the poll was concluded helps was put into account to keep track of how support for a candidate changes in time. The reported end dates in the original dataset [@fivethirtyeight2024] ranges from 1 January, 2023 to 9 September, 2024 (@tbl-date). @fig-date shows that the polling data is more concentrated on survey results conducted in the recent period.

```{r}
#| label: tbl-date
#| tbl-cap: Summary Statistics for the 'end_date' Variable (Raw Data)
#| echo: false

summary_stats <- raw_elections_data %>%
  summarize(
    min = min(end_date, na.rm = TRUE),
    max = max(end_date, na.rm = TRUE)
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```
```{r}
#| label: fig-date
#| fig-cap: Distribution of the 'end_date' Variable (Raw Data)
#| echo: false

# Convert 'end_date' to a proper date format
raw_elections_dataa <- raw_elections_data %>%
  mutate(end_date = mdy(end_date))
filtered_data <- raw_elections_dataa %>%
  filter(end_date >= as.Date("2023-01-01"))

# Distribution of 'end_date'
ggplot(filtered_data, aes(x = end_date)) +
  geom_histogram(fill = "grey", alpha = 0.7, color = "black", binwidth = 30) +  # Set binwidth explicitly
  theme_minimal() +
  labs(x = "End Date",
       y = "Count")

```

[!!! MODIFY DATE RANGE AFTER DATA UPDATES !!!] - ERASE AT FINAL

When filtering the data, not only pollster quality and candidate type but also the date variable was considered. The filtered data contains only the polling data after the declaration of Harris. So, the date variable for filtered data ranges from 23 July, 2024 to 14 October, 2024 (@tbl-date2). @fig-date2 shows that overall, polling is conducted regularly but intensifies around specific dates.

```{r}
#| label: tbl-date2
#| tbl-cap: Summary Statistics for the 'end_date' Variable (Filtered Data)
#| echo: false

summary_stats <- harris_data %>%
  summarize(
    min = min(end_date, na.rm = TRUE),
    max = max(end_date, na.rm = TRUE)
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

```{r}
#| label: fig-date2
#| fig-cap: Distribution of the 'end_date' Variable (Filtered Data)
#| echo: false

# Convert 'end_date' to a proper date format
harris_dataa <- harris_data %>%
  mutate(end_date = ymd(end_date))  # Change mdy() to ymd() or dmy() depending on the format

# Distribution of 'end_date'
ggplot(harris_dataa, aes(x = end_date)) +
  geom_histogram(fill = "grey", alpha = 0.7, color = "black", binwidth = 10) +  # Set binwidth explicitly
  theme_minimal() +
  labs(x = "End Date",
       y = "Count")

```

### pollster, state

The 'pollster' and 'state' variable were selected to consider the effect of changes in poll-making organizations and geographical distinctions. The two variables respectively represent the polling organization that conducted the poll and the US state where the poll was conducted or focused.

@tbl-predictors shows that the original dataset [@fivethirtyeight2024] contains 222 distinct pollsters and 54 distinct states. After filtering for high-quality polls and assigning 'other' for states with fewer than 60 polls, the analysis data contains 3 distinct poll-making organizations and 19 geographical distinctions as shown in @tbl-predictors.

```{r}
#| label: tbl-predictors
#| tbl-cap: Number of Distinct Values for the 'pollster', 'state' Variable (Raw Data)
#| echo: false

summary_stats <- raw_elections_data %>%
  summarize(
    pollsters = n_distinct(pollster),
    states = n_distinct(state)
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

```{r}
#| label: tbl-predictors
#| tbl-cap: Number of Distinct Values for the 'pollster', 'state' Variable (Filtered Data)
#| echo: false

summary_stats <- harris_data %>%
  summarize(
    pollsters = n_distinct(pollster),
    states = n_distinct(state)
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

The distribution of polling counts for different pollsters in @fig-pollster suggests that the analysis data is dominated by a few pollsters, particularly Siena/NYT. Depending on their polling methodology, the general results may have potential biases. A detailed analysis of the polling methodology and possible errors of the organization will be covered in @sec-data-details.

```{r}
#| label: fig-pollster
#| fig-cap: Distribution of the 'pollster' Variable (Filtered Data for Harris)
#| echo: false

# Distribution of 'pollster' (bar plot since it's categorical)
ggplot(harris_data, aes(x = pollster)) +
  geom_bar(fill = "purple", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "Pollster",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

@fig-state displays the distribution of polls across different states in the analysis data. Pennsylvania, Arizona, and Georgia are the top 3 states with high number of polls while states like Montana, New Mexico, and Maryland have much fewer polls. Note that a significant number of national or unspecified state-level polls are aggregated in this analysis data regarding the high count in 'Other' category. The concentration of polls in certain states further suggests a strategic focus on areas likely to impact the election outcome [@11alive2024].

```{r}
#| label: fig-state
#| fig-cap: Distribution of the 'state' Variable (Filtered Data for Harris)
#| echo: false

# Distribution of 'state' (bar plot)
ggplot(harris_data, aes(x = reorder(state, -table(state)[state]))) +
  geom_bar(fill = "black", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "State",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

### pollscore

This variable was another factor we had put into consideration to check whether the validity of the polling questions affects the polling results. The 'pollscore' variable represents the score or reliability of the pollster in question. The numeric values are the error and bias that can be attributed to the pollster, which means negative numbers are better. @tbl-pollscore and @fig-pollscore suggests that while the majority of the polls are moderately to highly qualitative in the original dataset, a fraction of the polls with low-quality or no scores could add noise or uncertainty to the analysis.

```{r}
#| label: tbl-pollscore
#| tbl-cap: Summary statistics for the 'pollscore' Variable (Raw Data)
#| echo: false

summary_stats <- raw_elections_data %>%
  summarize(
    mean = mean(pollscore, na.rm = TRUE),
    median = median(pollscore, na.rm = TRUE),
    min = min(pollscore, na.rm = TRUE),
    max = max(pollscore, na.rm = TRUE),
    sd = sd(pollscore, na.rm = TRUE),
    n = n()
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

```{r}
#| label: fig-pollscore
#| fig-cap: Distribution of the 'pollscore' Variable (Raw Data)
#| echo: false


# Distribution of 'pollscore' (bar plot)
ggplot(raw_elections_data, aes(x = factor(pollscore))) +
  geom_bar(fill = "skyblue", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "Pollscore",
       y = "Count")

```

After the filtering to polling data of high-quality polling organizations, we can find that the overall value and standard deviation of pollscores went down in @tbl-pollscore2. This implies that the polling data narrowed down to the responses from more reliable survey questions. @fig-pollscore2 also indicates that the data cleaning process effectively excluded less reliable sources, which can enhance the robustness of subsequent analyses.

```{r}
#| label: tbl-pollscore2
#| tbl-cap: Summary statistics for the 'pollscore' Variable (Filtered Data)
#| echo: false

summary_stats <- harris_data %>%
  summarize(
    mean = mean(pollscore, na.rm = TRUE),
    median = median(pollscore, na.rm = TRUE),
    min = min(pollscore, na.rm = TRUE),
    max = max(pollscore, na.rm = TRUE),
    sd = sd(pollscore, na.rm = TRUE),
    n = n()
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

```{r}
#| label: fig-pollscore2
#| fig-cap: Distribution of the 'pollscore' Variable (Filtered Data)
#| echo: false


# Distribution of 'pollscore' (bar plot)
ggplot(harris_data, aes(x = factor(pollscore))) +
  geom_bar(fill = "skyblue", alpha = 0.7, color = "black", width = 0.5) +
  theme_minimal() +
  labs(x = "Pollscore",
       y = "Count")

```

# Model {#sec-model}

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results {#sec-results}

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false


```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false


```




# Discussion {#sec-discussion}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix


# Additional data details {#sec-data-details}

## Pollster Methodology Overview and Evaluation

## Idealized Methodolgy

## Idealized Survey

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]


```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2


```



\newpage


# References


