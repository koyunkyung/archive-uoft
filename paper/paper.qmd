---
title: "Kamala Harris Rises as the 2024 Election Front Runner: A Poll-of-Polls Forecast"
subtitle: "How Poll Aggregation Reveals US Presidental Race Trends"
author: 
  - Yunkyung Ko
thanks: "Code and data are available at: [https://github.com/koyunkyung/us_election_2024](https://github.com/koyunkyung/us_election_2024)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
toc: true
toc-title: "Table of Contents"
toc-depth: 2
toc-location: left
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(readr)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(splines)
library(ggplot2)
library(knitr)
library(kableExtra)
library(gridExtra)
library(here)

raw_elections_data <- read_csv(here::here("data/01-raw_data/raw_elections_data.csv"))
harris_data <- read_csv(here::here("data/02-analysis_data/harris_elections_data.csv"))
```


# Introduction

The US presidential election is an event that receives a lot of international attention due to its far-reaching implications beyond the country's borders. The effects of US elections are not only related to economy and international relations around the world, but also link to social and environmental issues such as climate change [@euromonitor2024]. In the anticipation of the 2024 US electoral competition, this paper is aimed at predicting possible outcomes of the election by analyzing the level of support that Kamala Harris will gain.

We forecast the support of Kamala Harris based on the polling results at the national and state levels, and apply a linear regression and a Bayesian approach. The main parameter of interest is the proportion of vote or support that Harris received in surveys, which is traced over time. By considering the effect of changes in poll-making organizations and geographical distinctions, our objective is to correct for variation across different voter bases with the pooling the polls approach [@poolingpolls]. 

Our initial linear model examining the support for Harris over time suggests that the rate of support remained relatively stable around 47%, with no significant increase or decrease. However large variability was detected, as seen in the spread of points around the fitted line. Consequently, pollster-specific effects and state-level random effects were added to the model but resulted in even higher variations. Some pollsters or states consistently reported higher or lower support for Harris compared to others, proposing that [!!!!!MEANINGFUL RESULT ADDED LATER!!!!!].

These prognostics provide much more than merely forecasting the election in question. Hinting the trajectory the US might take in matters of foreign policy, economics, and global politics, predictions enable stakeholders worldwide to take preemptive measures for the resulted changes of a newly elected government [@csis2024]. As such, this study not only contributes to the domestic political discourse but also provides a valuable tool for global actors seeking to navigate the uncertainty surrounding the 2024 US presidential election[@csis2024].

The paper is structured as follows. Initially, @sec-data and @sec-model explores the data and methodology used, including filtering and modeling techniques applied to the polling data. Following that, @sec-results presents the results from the linear and Bayesian models, while the next section @sec-discussion discusses the broader implications of these findings. Finally, the paper concludes with remarks on future directions for research and applications of these models [@sec-discussion].


# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR] to analyze US presidential polling data from FiveThirtyEight [@fivethirtyeight2024], focusing on support for Kamala Harris. The dataset includes a wide range of poll results from various national and state-level polls, with key variables such as pollster, sample size, percentage of support for Harris, and end date of the poll. Following the guidance of @tellingstories, we compiled the results of each opinion poll over a period of time and compared them taking into account the methodological peculiarities of polling by pollsters and geographical scope of the conducted polls. 

To ensure data quality, we filtered the dataset to include only polls that measured Kamala Harris' support, with a numeric grade of pollster 2.7 or higher for reliability. We also limited the analysis to polls conducted after July 21, 2024, when Harris officially declared her candidacy, and excluded pollsters with fewer than 30 polls to focus on those with sufficient data for robust results.

In performing the analysis, we utilized several R packages. @tidyverse was used for data manipulation and visualization and @rstanarm, @modelsummary was respectively used for Bayesian modeling and generating model summaries. For visualizing results, @ggplot2 was used and @kableExtra helped format tables for presentation. These packages provided a framework for efficient data processing, modeling, and reporting.

(Data last updated on [Day] [Month] 2024.) - [!!! MODIFY AT FINAL !!!]

## Measurement

[!!! MODIFY OBSV. NUMBERS AFTER DATA UPDATES !!!] - ERASE AT FINAL

The original dataset sourced from FiveThirtyEight [@fivethirtyeight2024] aggregates a wide range of poll results (15971 observations, based on dataset available at Oct 21, 22:00). The polls conducted by various polling organizations capture voter preferences by taking a representative sample of the electorate and asking for the voters' candidate of choice. Surveys were conducted at the state and national levels, providing the wide perspective on public feelings across the country.

Each poll represents a predictor of an actual event, namely voter opinion at a particular moment. Nevertheless, like all survey results, the raw data is susceptible to many potential limitations including the following: sampling error, variation in polling methods, distortion because of inappropriate survey responses such as missing data or response from respondents who misunderstood the questions [@tellingstories].

While applying several filters to the original dataset such as restricting to those with a numeric grade of 2.7 or higher or pollsters with more than 30 polls improves data reliability, certain limitations still exist. Selection bias and sampling error remains as a concern, since polls always represent only part of the population. Differences in the way different organizations conducted their polling might introduce more inconsistencies. Finally, by focusing our attention on post-declaration polls only, we exclude earlier trends that could add more insight into how Harris' support has evolved over time. 

## Outcome variables

### pct

The main variable of interest that we aim to forecast is the 'pct' variable, which represents the proportion of vote or support that a candidate received in the poll. @tbl-pctraw1 and @fig-pct2 respectively shows the summary statistics and distribution of the 'pct' variable in the original dataset [@fivethirtyeight2024]. @tbl-pctfilter1 and @fig-pctfilter2 shows the summary statistics and distribution of the same variable, but in the filtered dataset that only comprises of the supporting votes for Harris from relatively high-quality polling organizations. Comparing the summary statistics for the raw data (@tbl-pctraw1) and filtered data (@tbl-pctfilter1), higher numbers were derived from data filtered only by Harris supporters. Also, @fig-pctfilter2 illustrates that a significant number of polls indicate support levels ranging from 40% to 50%, which suggests a stable yet not substantial endorsement. This proposes that Harris possesses a reliable foundational support, although her capacity to obtain a majority remains ambiguous.

```{r}
#| label: tbl-pctraw1
#| tbl-cap: Summary Statistics for the 'pct' Variable (Raw Data)
#| echo: false

# Calculate summary statistics for the 'pct' variable
summary_stats <- raw_elections_data %>%
  summarize(
    mean = mean(pct, na.rm = TRUE),
    median = median(pct, na.rm = TRUE),
    min = min(pct, na.rm = TRUE),
    max = max(pct, na.rm = TRUE),
    sd = sd(pct, na.rm = TRUE),
    n = n()
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```
```{r}
#| label: fig-pct2
#| fig-cap: Distribution of the 'pct' Variable (Raw Data)
#| echo: false

# Plot the distribution of 'pct' using a histogram
ggplot(raw_elections_data, aes(x = pct)) +
  geom_histogram(binwidth = 5, fill = "blue", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "Percentage of Support (pct)",
       y = "Frequency")

```
```{r}
#| label: tbl-pctfilter1
#| tbl-cap: Summary Statistics for the 'pct' Variable (Filtered Data)
#| echo: false

# Calculate summary statistics for the 'pct' variable
summary_stats <- harris_data %>%
  summarize(
    mean = mean(pct, na.rm = TRUE),
    median = median(pct, na.rm = TRUE),
    min = min(pct, na.rm = TRUE),
    max = max(pct, na.rm = TRUE),
    sd = sd(pct, na.rm = TRUE),
    n = n()
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```
```{r}
#| label: fig-pctfilter2
#| fig-cap: Distribution of the 'pct' Variable (Filtered Data)
#| echo: false

# Plot the distribution of 'pct' using a histogram
ggplot(harris_data, aes(x = pct)) +
  geom_histogram(binwidth = 5, fill = "blue", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "Percentage of Support (pct)",
       y = "Frequency")

```


## Predictor variables

### end_date

[!!! MODIFY DATE RANGE AFTER DATA UPDATES !!!] - ERASE AT FINAL

The date variable representing the time the poll was concluded helps was put into account to keep track of how support for a candidate changes in time. The reported end dates in the original dataset [@fivethirtyeight2024] ranges from 1 January, 2023 to 9 September, 2024 (@tbl-date). @fig-date shows that the polling data is more concentrated on survey results conducted in the recent period.

```{r}
#| label: tbl-date
#| tbl-cap: Summary Statistics for the 'end_date' Variable (Raw Data)
#| echo: false

summary_stats <- raw_elections_data %>%
  summarize(
    Min = min(end_date, na.rm = TRUE),
    Max = max(end_date, na.rm = TRUE)
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```
```{r}
#| label: fig-date
#| fig-cap: Distribution of the 'end_date' Variable (Raw Data)
#| echo: false

# Convert 'end_date' to a proper date format
raw_elections_dataa <- raw_elections_data %>%
  mutate(end_date = mdy(end_date))
filtered_data <- raw_elections_dataa %>%
  filter(end_date >= as.Date("2023-01-01"))

# Distribution of 'end_date'
ggplot(filtered_data, aes(x = end_date)) +
  geom_histogram(fill = "grey", alpha = 0.7, color = "black", binwidth = 30) +  # Set binwidth explicitly
  theme_minimal() +
  labs(x = "End Date",
       y = "Count")

```

[!!! MODIFY DATE RANGE AFTER DATA UPDATES !!!] - ERASE AT FINAL

When filtering the data, not only pollster quality and candidate type but also the date variable was considered. The filtered data contains only the polling data after the declaration of Harris. So, the date variable for filtered data ranges from 23 July, 2024 to 14 October, 2024 (@tbl-date2). @fig-date2 shows that overall, polling is conducted regularly but intensifies around specific dates.

```{r}
#| label: tbl-date2
#| tbl-cap: Summary Statistics for the 'end_date' Variable (Filtered Data)
#| echo: false

summary_stats <- harris_data %>%
  summarize(
    Min = min(end_date, na.rm = TRUE),
    Max = max(end_date, na.rm = TRUE)
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

```{r}
#| label: fig-date2
#| fig-cap: Distribution of the 'end_date' Variable (Filtered Data)
#| echo: false

# Convert 'end_date' to a proper date format
harris_dataa <- harris_data %>%
  mutate(end_date = ymd(end_date))  # Change mdy() to ymd() or dmy() depending on the format

# Distribution of 'end_date'
ggplot(harris_dataa, aes(x = end_date)) +
  geom_histogram(fill = "grey", alpha = 0.7, color = "black", binwidth = 10) +  # Set binwidth explicitly
  theme_minimal() +
  labs(x = "End Date",
       y = "Count")

```

### pollster, state

The 'pollster' and 'state' variable were selected to consider the effect of changes in poll-making organizations and geographical distinctions. The two variables respectively represent the polling organization that conducted the poll and the US state where the poll was conducted or focused.

@tbl-predictors1 shows that the original dataset [@fivethirtyeight2024] contains 222 distinct pollsters and 54 distinct states. After filtering for high-quality polls and assigning 'other' for states with fewer than 60 polls, the analysis data contains 3 distinct poll-making organizations and 19 geographical distinctions as shown in @tbl-predictors2.

```{r}
#| label: tbl-predictors1
#| tbl-cap: Number of Distinct Values for the 'pollster', 'state' Variable (Raw Data)
#| echo: false

summary_stats <- raw_elections_data %>%
  summarize(
    Pollster = n_distinct(pollster),
    State = n_distinct(state)
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

```{r}
#| label: tbl-predictors2
#| tbl-cap: Number of Distinct Values for the 'pollster', 'state' Variable (Filtered Data)
#| echo: false

summary_stats <- harris_data %>%
  summarize(
    Pollster = n_distinct(pollster),
    State = n_distinct(state)
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

The distribution of polling counts for different pollsters in @fig-pollster suggests that the analysis data is dominated by a few pollsters, particularly Siena/NYT. Depending on their polling methodology, the general results may have potential biases. A detailed analysis of the polling methodology and possible errors of the organization will be covered in @sec-data-details.

```{r}
#| label: fig-pollster
#| fig-cap: Distribution of the 'pollster' Variable (Filtered Data for Harris)
#| echo: false

# Distribution of 'pollster' (bar plot since it's categorical)
ggplot(harris_data, aes(x = pollster)) +
  geom_bar(fill = "purple", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "Pollster",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

@fig-state displays the distribution of polls across different states in the analysis data. Pennsylvania, Arizona, and Georgia are the top 3 states with high number of polls while states like Montana, New Mexico, and Maryland have much fewer polls. Note that a significant number of national or unspecified state-level polls are aggregated in this analysis data regarding the high count in 'Other' category. The concentration of polls in certain states further suggests a strategic focus on areas likely to impact the election outcome [@11alive2024].

```{r}
#| label: fig-state
#| fig-cap: Distribution of the 'state' Variable (Filtered Data for Harris)
#| echo: false

# Distribution of 'state' (bar plot)
ggplot(harris_data, aes(x = reorder(state, -table(state)[state]))) +
  geom_bar(fill = "black", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "State",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

### pollscore

This variable was another factor we had put into consideration to check whether the validity of the polling questions affects the polling results. The 'pollscore' variable represents the score or reliability of the pollster in question. The numeric values are the error and bias that can be attributed to the pollster, which means negative numbers are better. @tbl-pollscore and @fig-pollscore suggests that while the majority of the polls are moderately to highly qualitative in the original dataset, a fraction of the polls with low-quality or no scores could add noise or uncertainty to the analysis.

```{r}
#| label: tbl-pollscore
#| tbl-cap: Summary statistics for the 'pollscore' Variable (Raw Data)
#| echo: false

summary_stats <- raw_elections_data %>%
  summarize(
    mean = mean(pollscore, na.rm = TRUE),
    median = median(pollscore, na.rm = TRUE),
    min = min(pollscore, na.rm = TRUE),
    max = max(pollscore, na.rm = TRUE),
    sd = sd(pollscore, na.rm = TRUE),
    n = n()
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

```{r}
#| label: fig-pollscore
#| fig-cap: Distribution of the 'pollscore' Variable (Raw Data)
#| echo: false


# Distribution of 'pollscore' (bar plot)
ggplot(raw_elections_data, aes(x = factor(pollscore))) +
  geom_bar(fill = "skyblue", alpha = 0.7, color = "black") +
  theme_minimal() +
  labs(x = "Pollscore",
       y = "Count")

```

After the filtering to polling data of high-quality polling organizations, we can find that the overall value and standard deviation of pollscores went down in @tbl-pollscore2. This implies that the polling data narrowed down to the responses from more reliable survey questions. @fig-pollscore2 also indicates that the data cleaning process effectively excluded less reliable sources, which can enhance the robustness of subsequent analyses.

```{r}
#| label: tbl-pollscore2
#| tbl-cap: Summary statistics for the 'pollscore' Variable (Filtered Data)
#| echo: false

summary_stats <- harris_data %>%
  summarize(
    mean = mean(pollscore, na.rm = TRUE),
    median = median(pollscore, na.rm = TRUE),
    min = min(pollscore, na.rm = TRUE),
    max = max(pollscore, na.rm = TRUE),
    sd = sd(pollscore, na.rm = TRUE),
    n = n()
  )

# Display the summary statistics in a nicely formatted table
summary_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

```

```{r}
#| label: fig-pollscore2
#| fig-cap: Distribution of the 'pollscore' Variable (Filtered Data)
#| echo: false


# Distribution of 'pollscore' (bar plot)
ggplot(harris_data, aes(x = factor(pollscore))) +
  geom_bar(fill = "skyblue", alpha = 0.7, color = "black", width = 0.5) +
  theme_minimal() +
  labs(x = "Pollscore",
       y = "Count")

```

# Model {#sec-model}

The goal of our modelling strategy is to estimate Kamala Harris's support percentage in the 2024 US election polls, accounting for potential variations over time, as well as across different pollsters and states. The model balances complexity with interpretability, incorporating both linear and Bayesian frameworks to capture patterns in the data. Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the percentage of support that Kamala Harris receives in poll $i$. We begin with two simple linear models and progress to more complex Bayesian models that account for hierarchical structures.

The following models outline our approach:

### Linear Model by Date 

```{=latex}
\begin{align}  
y_i &= \beta_0 + \beta_1 \cdot \text{end\_date}_i + \epsilon_i \\
\epsilon_i &\sim \text{Normal}(0, \sigma^2)
\end{align}
```

where:
- $y_i$ is the percentage of support for Harris in poll $i$,
- $\beta_0$ is the intercept,
- $\beta_1$ represents the effect of the poll's end date,
- $\epsilon_i$ is the error term.

### Linear Model by Date and Pollster

```{=latex}
\begin{align}  
y_i &= \beta_0 + \beta_1 \cdot \text{end\_date}_i + \gamma_{p[i]} + \epsilon_i \\
\epsilon_i &\sim \text{Normal}(0, \sigma^2)
\end{align}
```

where:
- $\gamma_{p[i]}$ is a fixed effect for pollster $p$ conducting poll $i$ (e.g., Siena/NYT).

### Bayesian Model with Random Intercept for Pollster 

```{=latex}
\begin{align}  
y_i | \mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 \cdot \text{end\_date}_i + \gamma_{p[i]} \\
\gamma_p &\sim \text{Normal}(0, \sigma_{\gamma})
\end{align}
```

where:
- $\gamma_p$ is a random effect for pollster $p$.

### Bayesian Model with Random Intercept for Pollster and State

```{=latex}
\begin{align}  
y_i | \mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 \cdot \text{end\_date}_i + \gamma_{p[i]} + \delta_{s[i]} \\
\gamma_p &\sim \text{Normal}(0, \sigma_{\gamma}) \\
\delta_s &\sim \text{Normal}(0, \sigma_{\delta})
\end{align}
```

where:
- $\delta_{s[i]}$ is a random effect for state $s$.

The Bayesian models are fit using `rstanarm` in R. The priors used are weakly informative:
- $\beta_0 \sim \text{Normal}(0, 10)$
- $\sigma \sim \text{Exponential}(1)$

### Model justification

Different pollsters and states induce variations in polling results, as pollsters may have distinct methodologies and states represent diverse voter bases. Incorporating random effects for both pollsters and states allows us to improve the robustness of the model.

These models are run through the rstanarm package [@rstanarm] in R  [@citeR], which makes Bayesian modeling available through the use of Stan's strong inference engine. To validate the models, RMSE and WAIC have been made use of to check the goodness of fit; Bayesian models with reduced RMSE and WAIC outperform linear models. We use weakly informative priors; for example, $\beta_0 \sim \text{Normal}(0, 10)$ and $\sigma \sim \text{Exponential}(1)$. This reflects our initial uncertainty but prevents overfitting. The priors were chosen conservatively to ensure that the model remains consistent.

Model diagnostics, including posterior predictive checks and convergence diagnostics, were carried out to ensure the reliability of the results. The Bayesian models converged successfully, as indicated by $\hat{R} = 1$ for all parameters.

The main assumption in these models is that the pollster and state effects can be treated as random. This assumes that the effects are normally distributed across pollsters and states, which may not always be accurate. Additionally, the model assumes that polling data is representative of the actual electorate, an assumption that can be violated if polls are biased or have non-random sampling issues. Despite these limitations, the hierarchical structure allows us to capture important variability, making the model suitable for predicting Harris's support. Future improvements could involve incorporating time-varying effects or exploring interactions between pollsters and states.

# Results {#sec-results}

Our results are summarized in @tbl-modelresults1 and @tbl-modelresults2.
[!!! ADD MORE WORDS !!!]

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

model_date <-
  readRDS(file = here::here("models/model_date.rds"))

model_date_pollster <-
  readRDS(file = here::here("models/model_date_pollster.rds"))

bayesian_model_1 <-
  readRDS(file = here::here("models/bayesian_model_1.rds"))
  
bayesian_model_2 <-
  readRDS(file = here::here("models/bayesian_model_2.rds"))

```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults1
#| tbl-cap: "Linear models of support percentages for Harris based on date and pollster"
#| warning: false

modelsummary(
  list(
    "Linear by Date" = model_date,
    "Linear by Date, Pollster" = model_date_pollster
  ),
  statistic = "mad",
  fmt = 2)

```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults2
#| tbl-cap: "Bayesian models of support percentages for Harris based on pollster and state"
#| warning: false

modelsummary(
  list(
    "Bayesian with Pollster" = bayesian_model_1,
    "Bayesian with Pollster, State" = bayesian_model_2
  ),
  statistic = "mad",
  fmt = 2)

```


# Discussion {#sec-discussion}


## Stability in Support Levels for Harris {#sec-first-point}



## Pollster-Specific Variability {#sec-second-point}



## State-Level Differences {#sec-third-point}



## Weaknesses and next steps

Future studies could focus on the incorporation of time-varying effects to capture dynamic shifts in public opinion, especially at times of large campaign events. Interaction terms between pollster and state can be included in the model, since some polling organizations may be more effective or influential in specific regions. This can give further explanation to how pollsters and regional dynamics affect overall support for a candidate. Moreover, extending the model to incorporate voter demographics, such as age, gender, and education, could show which segments of the population are driving changes in support.

While our model provides a foundation to understand Harris' polling support, it will take further refinements are necessary to enhance its accuracy and applicability. The combination of hierarchical modeling with Bayesian methods is effective at accounting for the heterogeneity across pollsters and states, yet there remain considerable directions of inquiry to explore at the intersection of polling methodology, voter behavior, and regional electoral dynamics.

\newpage

\appendix

# Appendix

# Additional data details {#sec-data-details}

## Pollster Methodology Overview and Evaluation

The New York Times/Siena College polling partnership, the polling organization that accounted for the majority of polls in our analysis (@fig-pollster), conducts polls tailored for specific elections, such as state or national races [@nyt_siena_2020_methodology]. Their sample size typically includes 600 to 1000 likely voters per poll, with oversampling in battleground states to capture regional nuances [@nyt_siena_2020_methodology]. The methodology uses random-digit dialing (RDD) for landlines and mobile phones to ensure representative sample coverage across demographics. In addition, online surveys are administered to complement phone-based responses, ensuring broader accessibility [@nyt_siena_2020_methodology]. The stratified random sampling approach is employed, where the population is divided into strata (based on demographic variables like race, education, and geography), and a random sample is drawn from each stratum [@tellingstories]. This allows for precision in reflecting the political leanings and key demographic shifts in specific regions.

The organization intends to enhance transparency in how public opinion is assessed, ensuring that questions are carefully designed to represent contemporary political discussions, and that the terminology is polished through a process of iterative testing to achieve clarity. They devote extensive resources to cognitive testing to ensure question wording reflects what the public thinks [@siena_scri_2024_poll]. Their polling methodology stands out in that its strategic focus on using representative samples reflect political leanings and demographics of a region for more contextual and precise polling. Siena/NYT has its reputation for accurately predicting key battleground state outcomes during previous elections, such as Florida in 2016[@siena_nyt_perfect_partnership_2024].

The limitations of Siena/NYT's methodology are the challenge of polling itself. Since polling is a "snapshot in time",  the results can fluctuate based on recent political events or campaign dynamics. Additionally, while the effort to represent a broad demographic is laudable, there are still issues with nonresponse bias in polling-particularly among the hard-to-reach voter or voters suspicious of polling organizations themselves [@pew2023polling].


## Idealized Methodolgy

The proposed methodology for forecasting the 2024 U.S. presidential election with a budget of $100,000 would be designed as follows. First, a stratified random sampling method will be employed that allows for the capture of the demographic elements such as age, gender, race, and education level. This could alleviate bias and make the sample more representative of the population [@pew2023polling]. The data collection process will encompass both telephone surveys and internet polling, thereby effectively engaging a diverse range of voters [@pew2023polling]. Survey respondents would include older populations via conventional methods and younger, technologically intellectual individuals through digital platforms. This multifaceted approach enhances the reliability and inclusiveness of the gathered data.

In addition to robust sampling, the methodology incorporates weighting methods that account for groups that are underrepresented, ensuring that the outcomes are not skewed by sampling errors [@pew2023polling]. The final model would use Bayesian hierarchical modeling, which allows for more flexible modeling of uncertainty and variation across states, pollsters, and other external factors. These models, along with out-of-sample testing and cross-validation, enable accurate prediction sensitive to the dynamics of real-world changes, including political events [@pew2023polling]. The inclusion of external factors, such as major political events, debates, or sudden economic shifts, would help the model remain responsive to rapid changes in voter sentiment. 

## Idealized Survey

The proposed survey questionnarie design is provided in the following link: 

# Model details {#sec-model-details}

## Posterior predictive check

In the first posterior predictive check (@fig-ppcheck-1), we compare the observed data with replicated data generated from the posterior distribution. This shows that the model is able to replicate the overall distribution of the observed data, with the replicated curves (light blue) closely following the true data (dark blue line). This indicates that the model fits the data well in terms of capturing the main pattern or trend [@stan2023posteriorchecks].

In the second plot (@fig-ppcheck-2), the replicated data which had both the pollster and state variable as random intercepts, shows relatively closer approximation to the true data distribution. The narrowing of uncertainty in the posterior relative to the prior indicates the impact of the data on refining the model's predictions. This reassures that the model fits the data reasonably well and that the prior information has been appropriately updated by the observed data [@stan2023posteriorchecks].

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheck
#| layout-ncol: 2
#| fig-cap: "Examining how the Bayesian model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check"]

pp_check(bayesian_model_1) +
  theme_classic() +
  theme(legend.position = "bottom")

pp_check(bayesian_model_2) +
  theme_classic() +
  theme(legend.position = "bottom")
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. The sampled values for posterior distribution of intercept parameter across iterations of the MCMC algorithm shows good convergence [@stan_mcmc_traces]. The lines for the parameter appear to be stable and fluctuating around a central value without any clear trends or patterns. This suggests that the MCMC algorithm has likely converged, and the posterior samples are representative of the target distribution.

@fig-stanareyouokay-2 is a Rhat plot. The Rhat value is approximately 1.0 for the intercept, which shows that the variance within and between multiple chains have converged. An Rhat value close to 1 indicates that the chains have mixed well and are drawing from the same distribution while values significantly greater than 1 would indicate that further iterations are needed [@stan_mcmc_diagnostics].This suggests that the Bayesian models for both "pollster" and "state" have likely converged, and the results derived from these models are reliable.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2



plot(bayesian_model_1, pars = "(Intercept)", prob = 0.95)

plot(bayesian_model_2, pars = "(Intercept)", prob = 0.95)


```



\newpage


# References


